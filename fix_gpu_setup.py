#!/usr/bin/env python3
"""
GPU Setup Fix Script for Deep Live Cam
Run this if you're getting CPU execution provider instead of CUDA GPU
"""

import subprocess
import sys
import os

def check_current_setup():
    """Check current GPU and ONNX Runtime setup"""
    print("üîç Checking current setup...")
    
    # Check PyTorch CUDA
    try:
        import torch
        print(f"‚úÖ PyTorch version: {torch.__version__}")
        if torch.cuda.is_available():
            print(f"‚úÖ CUDA available: {torch.cuda.get_device_name(0)}")
            print(f"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
            print(f"   CUDA Version: {torch.version.cuda}")
        else:
            print("‚ùå CUDA not available in PyTorch")
            return False
    except ImportError:
        print("‚ùå PyTorch not installed")
        return False
    
    # Check ONNX Runtime
    try:
        import onnxruntime as ort
        print(f"‚úÖ ONNX Runtime version: {ort.__version__}")
        providers = ort.get_available_providers()
        print(f"   Available providers: {providers}")
        
        if 'CUDAExecutionProvider' in providers:
            print("‚úÖ CUDA execution provider available")
            return True
        else:
            print("‚ùå CUDA execution provider NOT available")
            return False
    except ImportError:
        print("‚ùå ONNX Runtime not installed")
        return False

def fix_onnxruntime():
    """Fix ONNX Runtime to use GPU"""
    print("\nüîß Fixing ONNX Runtime for GPU support...")
    
    # Uninstall existing ONNX Runtime packages
    print("Removing existing ONNX Runtime packages...")
    subprocess.run([
        sys.executable, "-m", "pip", "uninstall", "-y", 
        "onnxruntime", "onnxruntime-gpu", "onnxruntime-silicon"
    ], check=False)
    
    # Install GPU version
    print("Installing ONNX Runtime GPU...")
    subprocess.run([
        sys.executable, "-m", "pip", "install", "onnxruntime-gpu==1.16.3"
    ], check=True)
    
    print("‚úÖ ONNX Runtime GPU installed")

def test_gpu_execution():
    """Test if GPU execution is working"""
    print("\nüß™ Testing GPU execution...")
    
    try:
        import onnxruntime as ort
        
        # Create a session with CUDA provider
        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
        available_providers = ort.get_available_providers()
        
        print(f"Available providers: {available_providers}")
        
        if 'CUDAExecutionProvider' in available_providers:
            print("‚úÖ CUDA execution provider is available!")
            
            # Try to create a session (this will show which provider is actually used)
            print("Testing CUDA provider initialization...")
            session_options = ort.SessionOptions()
            
            # Create a dummy session to test
            try:
                # We'll use a simple model for testing, but for now just check provider availability
                print("‚úÖ GPU execution should work now!")
                return True
            except Exception as e:
                print(f"‚ö†Ô∏è  GPU provider available but may have issues: {e}")
                return False
        else:
            print("‚ùå CUDA execution provider still not available")
            return False
            
    except Exception as e:
        print(f"‚ùå Error testing GPU execution: {e}")
        return False

def show_usage_instructions():
    """Show how to use GPU acceleration"""
    print("\nüìã How to use GPU acceleration:")
    print("1. For command line:")
    print("   python run.py --execution-provider cuda")
    print()
    print("2. For web interface:")
    print("   python run_web.py  # Will auto-detect GPU")
    print()
    print("3. For Google Colab:")
    print("   python run_web_colab.py  # Auto-enables GPU")
    print()
    print("4. Check execution provider in use:")
    print("   Look for '[DLC.CORE] Applied providers: ['CUDAExecutionProvider']' in output")

def main():
    """Main function to fix GPU setup"""
    print("üöÄ Deep Live Cam - GPU Setup Fix")
    print("=" * 50)
    
    # Check current setup
    gpu_working = check_current_setup()
    
    if gpu_working:
        print("\n‚úÖ GPU setup looks good!")
        print("If you're still getting CPU execution, make sure to use:")
        print("python run.py --execution-provider cuda")
        show_usage_instructions()
        return
    
    # Ask user if they want to fix
    print(f"\n‚ùå GPU acceleration is not properly set up.")
    try:
        response = input("Do you want to fix it? (y/n): ").lower().strip()
        if response not in ['y', 'yes']:
            print("Exiting without changes.")
            return
    except (KeyboardInterrupt, EOFError):
        print("\nExiting without changes.")
        return
    
    # Try to fix
    try:
        fix_onnxruntime()
        
        # Re-check setup
        print("\nüîç Re-checking setup after fix...")
        gpu_working = check_current_setup()
        
        if gpu_working:
            print("\nüéâ GPU setup fixed successfully!")
            test_gpu_execution()
            show_usage_instructions()
        else:
            print("\n‚ùå GPU setup still not working. Possible issues:")
            print("1. No NVIDIA GPU available")
            print("2. CUDA toolkit not installed")
            print("3. Incompatible GPU driver")
            print("4. Running in CPU-only environment")
            
    except Exception as e:
        print(f"\n‚ùå Error during fix: {e}")
        print("You may need to manually install CUDA support.")

if __name__ == "__main__":
    main() 